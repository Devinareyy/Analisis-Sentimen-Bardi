---
title: "AlgoritmaNaiveBayes"
author: "123200021-123200114"
date: "2022-11-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tm)
library(wordcloud2)
library(vroom)
library(here)
library(RTextTools)
library(dplyr)
library(wordcloud)
library(shiny)
library(ggplot2)
library(plotly)
```

```{r Sentimen Analisis Naive Bayes Classifier}
library(e1071) #Untuk Naive Bayes
library(caret) #untuk Klasifikasi Data
library(syuzhet) #untuk membaca fungsi get_nrc
data <- read.csv("bardiclean.csv", stringsAsFactors =  FALSE)
review <- as.character(data$text) #merubah text menjadi char
s <- get_nrc_sentiment(review)
review_combine <- cbind(data$text,s) #klasifikasi Data
par(mar=rep(3,4))
a <- barplot(colSums(s), 
             col=c("#213A57", "#2B4D68", "#42647F", "#4A708B", "#4682B4", "#5C99CC", "#5CACEE", "#63B8FF", "#87CEFF", "#B0E2FF"),
             ylab='count',main='Sentiment Analisis Aplikasi Bardi')

brplt <- a
```
Memanggil library tambahan yang akan digunakan untuk penggunaan corpus dalam proses cleaning data selanjutnya, Mengatur seed generator bilangan acak R, yang berguna untuk membuat simulasi atau objek acak yang dapat direproduksi.

```{r}
require (corpus)
df<-read.csv("bardiclean.csv",stringsAsFactors = FALSE)
glimpse(df)
set.seed(20)
df<-df[sample(nrow(df)),]
df<-df[sample(nrow(df)),]
glimpse(df)
corpus<-Corpus(VectorSource(df$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan 
corpus.clean<-corpus%>%
    tm_map(content_transformer(tolower))%>%
    tm_map(removePunctuation)%>%
    tm_map(removeNumbers)%>%
    tm_map(removeWords, c("yang", "dan", "dari", "aasinya", "ini", "kita", "untuk" ,"nya","can","aasi"))%>%
    tm_map(removeWords,stopwords(kind="en"))%>%
    tm_map(stripWhitespace)

dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-df[1:50,]
df.test<-df[51:100,]                                            
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
corpus.clean.train<-corpus.clean[1:50]
corpus.clean.test<-corpus.clean[51:100]
dim(dtm.train)

fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
#dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}

trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)

wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))

#skoring
kalimat2<-read.csv("bardiclean.csv",header=TRUE)
kata.positif <- scan("kata-pos.txt",what="character",comment.char=";")
kata.negatif <- scan("kata-neg.txt",what="character",comment.char=";")
score.sentiment = function(kalimat2, kata.positif, kata.negatif,
                           .progress='none')
{
  require(plyr)
  require(stringr)
  scores = laply(kalimat2, function(kalimat, kata.positif,
                                    kata.negatif) {
    kalimat = gsub('[[:punct:]]', '', kalimat)
    kalimat = gsub('[[:cntrl:]]', '', kalimat)
    kalimat = gsub('\\d+', '', kalimat)
    kalimat = tolower(kalimat)
    list.kata = str_split(kalimat, '\\s+')
    kata2 = unlist(list.kata)
    positif.matches = match(kata2, kata.positif)
    negatif.matches = match(kata2, kata.negatif)
    positif.matches = !is.na(positif.matches)
    negatif.matches = !is.na(negatif.matches)
    score = sum(positif.matches) - (sum(negatif.matches))
    return(score)
  }, kata.positif, kata.negatif, .progress=.progress )
  scores.df = data.frame(score=scores, text=kalimat2)
  return(scores.df)}
hasil = score.sentiment(kalimat2$text, kata.positif, kata.negatif)
#mengubah nilai score menjadi sentimen
hasil$klasifikasi<- ifelse(hasil$score<0, "Negatif",ifelse(hasil$score==0,"Netral","Positif"))
hasil$klasifikasi
#menukar urutan baris
data <- hasil[c(3,1,2)]
#View(data)
write.csv(data, file = "datalabel.csv")
```
Pengolahan serta pemodelan dari sebuah data yang telah di olah sebelumnya hingga menampilkan pada GUI dengann Library Shiny

```{r}
dataLabel<- read.csv("datalabel.csv")
ui <- fluidPage(
    titlePanel( h1("Sentimen Analisis Ulasan Aplikasi Bardi", align = "center")),
        mainPanel(
            tabsetPanel(type = "tabs",
                        tabPanel("Bagan", plotOutput("bagan")), 
                        tabPanel("Wordcloud", plotOutput("Wordcloud", width = "500px", height = "500px")),
                        tabPanel("Data", DT::dataTableOutput('tbl1'))

                        )
        )
)
    
    
# SERVER 
server <- function(input, output) {
    
    # Output Data
    output$tbl1 = DT::renderDataTable({
        DT::datatable(dataLabel, options = list(lengthChange = FALSE))
    })
    
    #output bar
    output$bagan <- renderPlot({
      produk_dataset<-read.csv("bardiclean.csv",stringsAsFactors = FALSE)
      review <-as.character(produk_dataset$text)
      s<-get_nrc_sentiment(review)
      review_combine<-cbind(produk_dataset$text,s)
      par(mar=rep(3,4))
      barplot(colSums(s),
              col= c("#213A57", "#2B4D68", "#42647F", "#4A708B", "#4682B4", "#5C99CC", "#5CACEE", "#63B8FF",
                     "#87CEFF", "#B0E2FF"),
              ylab='count',main='Sentimen Analisis Ulasan Bardi')
    }, width = 800)
    
    #output word
    output$Wordcloud <- renderPlot({
      wordcloud(corpus.clean, min.freq = 4,max.words=100, random.order=F, colors=brewer.pal(8,"Dark2"))
    })
}
shinyApp(ui = ui, server = server)
```